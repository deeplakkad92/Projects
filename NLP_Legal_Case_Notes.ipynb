{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries for the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re \n",
    "import glob \n",
    "import xmltodict, json\n",
    "import string \n",
    "import nltk\n",
    "import gensim\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a function that extracts the content in the xml, converts into JSON and returns string as case_name_text and case_sentence_text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the xml file we are loading contains some error files which needed to be fixed. \n",
    "\n",
    "At first, when I tried loading it into pandas using the xmlparse library, I encountered an error. After validating the xml file online, I found that catchphrase tag had an error. \n",
    "\n",
    "So, I read the file as a text and split the text on the word \"catchphrases\" and joined the strings. Then, xml file doesn't support ampersand which needed to be taken care of. \n",
    "\n",
    "Now, for returning the clean text, I also remove the end of line characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    fopen = open(file).read()\n",
    "    fopen.split('catchphrases')[0]\n",
    "    clean_xml = fopen.split('catchphrases')[0][:-1] + fopen.split('catchphrases')[2][1:]\n",
    "    \n",
    "    text = ''\n",
    "    for i in clean_xml:\n",
    "        i = i.lower()\n",
    "        i = i.replace('&', '')\n",
    "        i = i.replace('\\n', '')\n",
    "        text += i\n",
    "    \n",
    "    o = xmltodict.parse(text)\n",
    "    text_injson_clean = json.dumps(o) \n",
    "    df = pd.read_json(text_injson_clean)   \n",
    "\n",
    "    for i in df.iloc[2,:]:\n",
    "        sentences = i['sentence']\n",
    "    \n",
    "    final_sentence = ''.join([i['#text'] for i in sentences])\n",
    "\n",
    "    for j in df.iloc[1,:]:\n",
    "        name = j[:]\n",
    "    return final_sentence, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading all the files that endswith .xml extension inside full text folder and loading it into pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for importing multiple xml file, I used glob function. \n",
    "\n",
    "This helped to fetch all the files that endswith \".xml\". After loading the xml file, passing it into open_file function which returns the list of the sentences text and list of the name of all cases. \n",
    "\n",
    "Than, I used regular expressions to remove all the digits and numbers from the text and also defined new column which has length of all the characters of the text which in short gives us length of each case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_data</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [case_data, case_name, case_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_name = []\n",
    "case_data = []\n",
    "for file in glob.glob('/Users/deeplakkad/Downloads/corpus/fulltext/*.xml'):\n",
    "    cs_str, cs_name = open_file(file)\n",
    "    case_name.append(cs_name)\n",
    "    case_data.append(cs_str)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "df = pd.DataFrame({'case_name': case_name, 'case_data': case_data})\n",
    "df['case_data'] = df['case_data'].apply(lambda x: re.sub('\\d+', '', x))\n",
    "df['case_length'] = df['case_data'].apply(lambda x: len(x) - x.count(' '))\n",
    "df.head(2)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the punctuation from the sentence text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just for the sake of simplicity, I created a new function which helps us to remove the punctuation characters in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_data</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on  april  the application brought by the university of western australia uwa against dr bruce ...</td>\n",
       "      <td>university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)</td>\n",
       "      <td>25406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction  the applicant seeks review of the respondents decision under s  of the administrat...</td>\n",
       "      <td>parker v parker [2009] fca 930 (25 august 2009)</td>\n",
       "      <td>23995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...</td>\n",
       "      <td>csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)</td>\n",
       "      <td>46188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>background to the appeal  this is an appeal against orders of the federal magistrates court of  ...</td>\n",
       "      <td>field v st george bank limited [2009] fca 1042 (17 september 2009)</td>\n",
       "      <td>51026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this matter came on for hearing before me yesterday on referral from the district registrars co...</td>\n",
       "      <td>deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)</td>\n",
       "      <td>18401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             case_data  \\\n",
       "0   on  april  the application brought by the university of western australia uwa against dr bruce ...   \n",
       "1  introduction  the applicant seeks review of the respondents decision under s  of the administrat...   \n",
       "2   the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...   \n",
       "3  background to the appeal  this is an appeal against orders of the federal magistrates court of  ...   \n",
       "4   this matter came on for hearing before me yesterday on referral from the district registrars co...   \n",
       "\n",
       "                                                                                         case_name  \\\n",
       "0                    university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)   \n",
       "1                                                  parker v parker [2009] fca 930 (25 august 2009)   \n",
       "2                 csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)   \n",
       "3                               field v st george bank limited [2009] fca 1042 (17 september 2009)   \n",
       "4  deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)   \n",
       "\n",
       "   case_length  \n",
       "0        25406  \n",
       "1        23995  \n",
       "2        46188  \n",
       "3        51026  \n",
       "4        18401  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def remove_punc(text):\n",
    "    text_nopun = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopun\n",
    "\n",
    "df['case_data'] = df['case_data'].apply(lambda x: remove_punc(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the sentence text into the list of individual words by tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the next step is to perform tokenization. So, basically this splits the text separated by comma and returns the list of individual words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_data</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_length</th>\n",
       "      <th>cd_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on  april  the application brought by the university of western australia uwa against dr bruce ...</td>\n",
       "      <td>university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)</td>\n",
       "      <td>25406</td>\n",
       "      <td>[, on, april, the, application, brought, by, the, university, of, western, australia, uwa, again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction  the applicant seeks review of the respondents decision under s  of the administrat...</td>\n",
       "      <td>parker v parker [2009] fca 930 (25 august 2009)</td>\n",
       "      <td>23995</td>\n",
       "      <td>[introduction, the, applicant, seeks, review, of, the, respondents, decision, under, s, of, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...</td>\n",
       "      <td>csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)</td>\n",
       "      <td>46188</td>\n",
       "      <td>[, the, applicant, csl, limited, csl, seeks, an, interlocutory, injunction, to, restrain, the, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>background to the appeal  this is an appeal against orders of the federal magistrates court of  ...</td>\n",
       "      <td>field v st george bank limited [2009] fca 1042 (17 september 2009)</td>\n",
       "      <td>51026</td>\n",
       "      <td>[background, to, the, appeal, this, is, an, appeal, against, orders, of, the, federal, magistrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this matter came on for hearing before me yesterday on referral from the district registrars co...</td>\n",
       "      <td>deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)</td>\n",
       "      <td>18401</td>\n",
       "      <td>[, this, matter, came, on, for, hearing, before, me, yesterday, on, referral, from, the, distric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             case_data  \\\n",
       "0   on  april  the application brought by the university of western australia uwa against dr bruce ...   \n",
       "1  introduction  the applicant seeks review of the respondents decision under s  of the administrat...   \n",
       "2   the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...   \n",
       "3  background to the appeal  this is an appeal against orders of the federal magistrates court of  ...   \n",
       "4   this matter came on for hearing before me yesterday on referral from the district registrars co...   \n",
       "\n",
       "                                                                                         case_name  \\\n",
       "0                    university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)   \n",
       "1                                                  parker v parker [2009] fca 930 (25 august 2009)   \n",
       "2                 csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)   \n",
       "3                               field v st george bank limited [2009] fca 1042 (17 september 2009)   \n",
       "4  deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)   \n",
       "\n",
       "   case_length  \\\n",
       "0        25406   \n",
       "1        23995   \n",
       "2        46188   \n",
       "3        51026   \n",
       "4        18401   \n",
       "\n",
       "                                                                                           cd_tokenize  \n",
       "0  [, on, april, the, application, brought, by, the, university, of, western, australia, uwa, again...  \n",
       "1  [introduction, the, applicant, seeks, review, of, the, respondents, decision, under, s, of, the,...  \n",
       "2  [, the, applicant, csl, limited, csl, seeks, an, interlocutory, injunction, to, restrain, the, r...  \n",
       "3  [background, to, the, appeal, this, is, an, appeal, against, orders, of, the, federal, magistrat...  \n",
       "4  [, this, matter, came, on, for, hearing, before, me, yesterday, on, referral, from, the, distric...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "df['cd_tokenize'] = df['case_data'].apply(lambda x: tokenize(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing all the common words in the text i.e. Dropping stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to remove the stopwords (i.e. the, by, on, etc.) because these words don't add information to our text that we are trying to get from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_data</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_length</th>\n",
       "      <th>cd_tokenize</th>\n",
       "      <th>cd_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on  april  the application brought by the university of western australia uwa against dr bruce ...</td>\n",
       "      <td>university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)</td>\n",
       "      <td>25406</td>\n",
       "      <td>[, on, april, the, application, brought, by, the, university, of, western, australia, uwa, again...</td>\n",
       "      <td>[, april, application, brought, university, western, australia, uwa, dr, bruce, gray, sirtex, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction  the applicant seeks review of the respondents decision under s  of the administrat...</td>\n",
       "      <td>parker v parker [2009] fca 930 (25 august 2009)</td>\n",
       "      <td>23995</td>\n",
       "      <td>[introduction, the, applicant, seeks, review, of, the, respondents, decision, under, s, of, the,...</td>\n",
       "      <td>[introduction, applicant, seeks, review, respondents, decision, administrative, decisions, judic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...</td>\n",
       "      <td>csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)</td>\n",
       "      <td>46188</td>\n",
       "      <td>[, the, applicant, csl, limited, csl, seeks, an, interlocutory, injunction, to, restrain, the, r...</td>\n",
       "      <td>[, applicant, csl, limited, csl, seeks, interlocutory, injunction, restrain, respondent, glaxosm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>background to the appeal  this is an appeal against orders of the federal magistrates court of  ...</td>\n",
       "      <td>field v st george bank limited [2009] fca 1042 (17 september 2009)</td>\n",
       "      <td>51026</td>\n",
       "      <td>[background, to, the, appeal, this, is, an, appeal, against, orders, of, the, federal, magistrat...</td>\n",
       "      <td>[background, appeal, appeal, orders, federal, magistrates, court, june, making, sequestration, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this matter came on for hearing before me yesterday on referral from the district registrars co...</td>\n",
       "      <td>deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)</td>\n",
       "      <td>18401</td>\n",
       "      <td>[, this, matter, came, on, for, hearing, before, me, yesterday, on, referral, from, the, distric...</td>\n",
       "      <td>[, matter, came, hearing, yesterday, referral, district, registrars, corporations, list, novembe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             case_data  \\\n",
       "0   on  april  the application brought by the university of western australia uwa against dr bruce ...   \n",
       "1  introduction  the applicant seeks review of the respondents decision under s  of the administrat...   \n",
       "2   the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...   \n",
       "3  background to the appeal  this is an appeal against orders of the federal magistrates court of  ...   \n",
       "4   this matter came on for hearing before me yesterday on referral from the district registrars co...   \n",
       "\n",
       "                                                                                         case_name  \\\n",
       "0                    university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)   \n",
       "1                                                  parker v parker [2009] fca 930 (25 august 2009)   \n",
       "2                 csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)   \n",
       "3                               field v st george bank limited [2009] fca 1042 (17 september 2009)   \n",
       "4  deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)   \n",
       "\n",
       "   case_length  \\\n",
       "0        25406   \n",
       "1        23995   \n",
       "2        46188   \n",
       "3        51026   \n",
       "4        18401   \n",
       "\n",
       "                                                                                           cd_tokenize  \\\n",
       "0  [, on, april, the, application, brought, by, the, university, of, western, australia, uwa, again...   \n",
       "1  [introduction, the, applicant, seeks, review, of, the, respondents, decision, under, s, of, the,...   \n",
       "2  [, the, applicant, csl, limited, csl, seeks, an, interlocutory, injunction, to, restrain, the, r...   \n",
       "3  [background, to, the, appeal, this, is, an, appeal, against, orders, of, the, federal, magistrat...   \n",
       "4  [, this, matter, came, on, for, hearing, before, me, yesterday, on, referral, from, the, distric...   \n",
       "\n",
       "                                                                                            cd_no_stop  \n",
       "0  [, april, application, brought, university, western, australia, uwa, dr, bruce, gray, sirtex, me...  \n",
       "1  [introduction, applicant, seeks, review, respondents, decision, administrative, decisions, judic...  \n",
       "2  [, applicant, csl, limited, csl, seeks, interlocutory, injunction, restrain, respondent, glaxosm...  \n",
       "3  [background, appeal, appeal, orders, federal, magistrates, court, june, making, sequestration, o...  \n",
       "4  [, matter, came, hearing, yesterday, referral, district, registrars, corporations, list, novembe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]\n",
    "    return text\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "df['cd_no_stop'] = df['cd_tokenize'].apply(lambda x: remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Lemmatization for converting the words to their roots using machine learning approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are two methods to check each word individually and return the root of that word. \n",
    "\n",
    "First one is stemming and second one is lemmatization. \n",
    "\n",
    "Although stemming is faster, it doesn't take the context of the word into account and replace with the root word whereas lemmatization is a more enhanced approach which takes the word into account and replace the word to it's root by taking the context into consideration. \n",
    "\n",
    "However, the two words differ in their flavor. \n",
    "\n",
    "Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. \n",
    "\n",
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma . \n",
    "\n",
    "If confronted with the token saw, stemming might return just s, whereas lemmatization would attempt to return either see or saw depending on whether the use of the token was as a verb or a noun. \n",
    "\n",
    "The two may also differ in that stemming most commonly collapses derivationally related words, whereas lemmatization commonly only collapses the different inflectional forms of a lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_data</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_length</th>\n",
       "      <th>cd_tokenize</th>\n",
       "      <th>cd_no_stop</th>\n",
       "      <th>cd_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on  april  the application brought by the university of western australia uwa against dr bruce ...</td>\n",
       "      <td>university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)</td>\n",
       "      <td>25406</td>\n",
       "      <td>[, on, april, the, application, brought, by, the, university, of, western, australia, uwa, again...</td>\n",
       "      <td>[, april, application, brought, university, western, australia, uwa, dr, bruce, gray, sirtex, me...</td>\n",
       "      <td>[, april, application, brought, university, western, australia, uwa, dr, bruce, gray, sirtex, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction  the applicant seeks review of the respondents decision under s  of the administrat...</td>\n",
       "      <td>parker v parker [2009] fca 930 (25 august 2009)</td>\n",
       "      <td>23995</td>\n",
       "      <td>[introduction, the, applicant, seeks, review, of, the, respondents, decision, under, s, of, the,...</td>\n",
       "      <td>[introduction, applicant, seeks, review, respondents, decision, administrative, decisions, judic...</td>\n",
       "      <td>[introduction, applicant, seek, review, respondent, decision, administrative, decision, judicial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...</td>\n",
       "      <td>csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)</td>\n",
       "      <td>46188</td>\n",
       "      <td>[, the, applicant, csl, limited, csl, seeks, an, interlocutory, injunction, to, restrain, the, r...</td>\n",
       "      <td>[, applicant, csl, limited, csl, seeks, interlocutory, injunction, restrain, respondent, glaxosm...</td>\n",
       "      <td>[, applicant, csl, limited, csl, seek, interlocutory, injunction, restrain, respondent, glaxosmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>background to the appeal  this is an appeal against orders of the federal magistrates court of  ...</td>\n",
       "      <td>field v st george bank limited [2009] fca 1042 (17 september 2009)</td>\n",
       "      <td>51026</td>\n",
       "      <td>[background, to, the, appeal, this, is, an, appeal, against, orders, of, the, federal, magistrat...</td>\n",
       "      <td>[background, appeal, appeal, orders, federal, magistrates, court, june, making, sequestration, o...</td>\n",
       "      <td>[background, appeal, appeal, order, federal, magistrate, court, june, making, sequestration, ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this matter came on for hearing before me yesterday on referral from the district registrars co...</td>\n",
       "      <td>deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)</td>\n",
       "      <td>18401</td>\n",
       "      <td>[, this, matter, came, on, for, hearing, before, me, yesterday, on, referral, from, the, distric...</td>\n",
       "      <td>[, matter, came, hearing, yesterday, referral, district, registrars, corporations, list, novembe...</td>\n",
       "      <td>[, matter, came, hearing, yesterday, referral, district, registrar, corporation, list, november,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             case_data  \\\n",
       "0   on  april  the application brought by the university of western australia uwa against dr bruce ...   \n",
       "1  introduction  the applicant seeks review of the respondents decision under s  of the administrat...   \n",
       "2   the applicant csl limited csl seeks an interlocutory injunction to restrain the respondent glax...   \n",
       "3  background to the appeal  this is an appeal against orders of the federal magistrates court of  ...   \n",
       "4   this matter came on for hearing before me yesterday on referral from the district registrars co...   \n",
       "\n",
       "                                                                                         case_name  \\\n",
       "0                    university of western australia v gray (no 21) [2008] fca 1056 (16 july 2008)   \n",
       "1                                                  parker v parker [2009] fca 930 (25 august 2009)   \n",
       "2                 csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)   \n",
       "3                               field v st george bank limited [2009] fca 1042 (17 september 2009)   \n",
       "4  deputy commissioner of taxation v bk ganter holdings pty ltd [2008] fca 1730 (18 november 2008)   \n",
       "\n",
       "   case_length  \\\n",
       "0        25406   \n",
       "1        23995   \n",
       "2        46188   \n",
       "3        51026   \n",
       "4        18401   \n",
       "\n",
       "                                                                                           cd_tokenize  \\\n",
       "0  [, on, april, the, application, brought, by, the, university, of, western, australia, uwa, again...   \n",
       "1  [introduction, the, applicant, seeks, review, of, the, respondents, decision, under, s, of, the,...   \n",
       "2  [, the, applicant, csl, limited, csl, seeks, an, interlocutory, injunction, to, restrain, the, r...   \n",
       "3  [background, to, the, appeal, this, is, an, appeal, against, orders, of, the, federal, magistrat...   \n",
       "4  [, this, matter, came, on, for, hearing, before, me, yesterday, on, referral, from, the, distric...   \n",
       "\n",
       "                                                                                            cd_no_stop  \\\n",
       "0  [, april, application, brought, university, western, australia, uwa, dr, bruce, gray, sirtex, me...   \n",
       "1  [introduction, applicant, seeks, review, respondents, decision, administrative, decisions, judic...   \n",
       "2  [, applicant, csl, limited, csl, seeks, interlocutory, injunction, restrain, respondent, glaxosm...   \n",
       "3  [background, appeal, appeal, orders, federal, magistrates, court, june, making, sequestration, o...   \n",
       "4  [, matter, came, hearing, yesterday, referral, district, registrars, corporations, list, novembe...   \n",
       "\n",
       "                                                                                         cd_lemmatized  \n",
       "0  [, april, application, brought, university, western, australia, uwa, dr, bruce, gray, sirtex, me...  \n",
       "1  [introduction, applicant, seek, review, respondent, decision, administrative, decision, judicial...  \n",
       "2  [, applicant, csl, limited, csl, seek, interlocutory, injunction, restrain, respondent, glaxosmi...  \n",
       "3  [background, appeal, appeal, order, federal, magistrate, court, june, making, sequestration, ord...  \n",
       "4  [, matter, came, hearing, yesterday, referral, district, registrar, corporation, list, november,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(tokenized_nostop):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_nostop]\n",
    "    return text\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "df['cd_lemmatized'] = df['cd_no_stop'].apply(lambda x: lemmatize(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the case and find the most occurring words in that case "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, counter creates the dictionary of each word as key and frequency as it's value. This helps to identify the words with most occurrences in our text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the case number: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gska', 104),\n",
       " ('cervarix', 79),\n",
       " ('csl', 76),\n",
       " ('information', 68),\n",
       " ('gardasil', 65),\n",
       " ('hpv', 64),\n",
       " ('vaccine', 62),\n",
       " ('sheet', 53),\n",
       " ('cancer', 51),\n",
       " ('would', 50)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_number = int(input('Enter the case number: '))\n",
    "counter = Counter(df['cd_lemmatized'][case_number])\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using gensim for creating a bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have used gensim to create a bag of words. It takes unique words into our tokenized list and converts into numbers to perform mathematical operations like SVM, Naive Bayes for classification problem, etc. or to perform TF-IDF method as equations can be performed on numbers rather than on text. So, this helps us to create a corpus and each unique word is identified in terms of 0,1,2, etc. and value of occurence in a given sentence. \n",
    "\n",
    "\n",
    "The function doc2bow() simply counts the number of occurrences of each distinct word, converts the word to its integer word id and returns the result as a sparse vector. The sparse vector [(0, 1), (1, 1)] therefore reads: in the document “Human computer interaction”, the words computer (id 0) and human (id 1) appear once; the other ten dictionary words appear (implicitly) zero times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in df['case_data']]\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TF-IDF method on our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VERY GOOD DEFINITION: http://www.tfidf.com/\n",
    "\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "Consider a document containing 100 words wherein the word cat appears 3 times. The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the case number: 2\n",
      "Name: csl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)\n",
      "gska 0.552368427388354\n",
      "cervarix 0.4195875554199997\n",
      "gardasil 0.34523026711772126\n",
      "hpv 0.33991903223898706\n",
      "csl 0.3020946312661078\n",
      "vaccine 0.2164461311281897\n",
      "cervical 0.14704101188738186\n",
      "tga 0.11582977313479494\n",
      "cancer 0.10678933379412729\n",
      "gskas 0.10091346269594928\n"
     ]
    }
   ],
   "source": [
    "case_number = int(input('Select the case number: '))\n",
    "case_name = df['case_name'][case_number]\n",
    "doc = corpus[case_number]\n",
    "print('Name: {}'.format(case_name))\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "tfidf_weights = tfidf[doc]\n",
    "\n",
    "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
    "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 10 weighted words\n",
    "for term_id, weight in sorted_tfidf_weights[:10]:\n",
    "    print(dictionary.get(term_id), weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Topic Modeling - Implementing LDA on our corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIKIPEDIA LINK: https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "\n",
    "In natural language processing, latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's creation is attributable to one of the document's topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the case numbers you want to study separated by comma: 2\n",
      "Case : 2\tcsl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)\n",
      "Keywords: ['decision\" ', ' act\" ', ' applicant\" ', ' tax\" ', ' made\" ', ' respondent\" ', ' review\" ', ' exercise\" ', ' commissioner\" ', ' adjr\"']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_numbers = input('Select the case numbers you want to study separated by comma: ')\n",
    "\n",
    "list_of_cases = case_numbers.split(',')\n",
    "for i in list_of_cases:\n",
    "    i = int(i)\n",
    "    j = i\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in df['cd_lemmatized'][i-1:j]]\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=4, update_every=4, chunksize=10000, passes=1)\n",
    "    print('Case : {}\\t{}'.format(j,df['case_name'][i]))\n",
    "    topic = re.sub('\\d+\\W+','',lda.print_topics(1)[0][1]).split('+')\n",
    "    print('Keywords: {}'.format(topic))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Parts of Speech tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as noticed in the above output generated by Latent Dirichlet Allocation, we can see that are words that includes NOUN i.e. 'applicant', 'respondent', etc. which aren't useful keywords for us because they tell nothing about the article. \n",
    "\n",
    "So, after applying pos_tag, we can see that model has highly improvised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the case number: 2\n",
      "Case : \tcsl limited v glaxosmithkline australia pty ltd [2006] fca 1301 (3 october 2006)\n",
      "Keywords: ['gska\" ', ' hpv\" ', ' csl\" ', ' information\" ', ' cervarix\" ', ' sheet\" ', ' vaccine\" ', ' gardasil\" ', ' cancer\" ', ' cervical\"']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pos_tagging(case_number):\n",
    "    data = []\n",
    "    cd_tokenize = []\n",
    "    tags = ['NNP', 'VBD']\n",
    "\n",
    "    for word in nltk.sent_tokenize(df.case_data[case_number]):\n",
    "        data = data + nltk.pos_tag(nltk.word_tokenize(word))\n",
    "\n",
    "        for word in data:\n",
    "            if word[1] in tags:\n",
    "                cd_tokenize.append('')\n",
    "            else:\n",
    "                cd_tokenize.append(word[0])\n",
    "    cd_no_stop = remove_stopwords(cd_tokenize)\n",
    "    cd_lemmatize = lemmatize(cd_no_stop)\n",
    "    terms = [cd_lemmatize]\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in terms]\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=4, update_every=4, chunksize=10000, passes=1)\n",
    "    print('Case : \\t{}'.format(df['case_name'][case_number]))\n",
    "    topic = re.sub('\\d+\\W+','',lda.print_topics(1)[0][1]).split('+')\n",
    "    print('Keywords: {}'.format(topic))\n",
    "    print('\\n')\n",
    "    \n",
    "        \n",
    "case_number = int(input('Select the case number: '))\n",
    "pos_tagging(case_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Goal: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: \n",
    "\n",
    "PERFORMING BIGRAMS: \n",
    "\n",
    "We can perform Bigrams for the sentence text in each case and check the occurrence of words that are in pair. This can give us more information about the case. \n",
    "\n",
    "Second: \n",
    "\n",
    "We can remove the words that are smaller than 3 characters in length. This will help us to identify if there are any single character words such as 'c', 'mr', 'dr', etc. \n",
    "\n",
    "I haven't used because sometimes we use 'br' for bankrupty which is important. So, after identify the case we will be more to implement it as well. \n",
    "\n",
    "Third: \n",
    "\n",
    "Also, due to time constraint and performing two project, unfortunately I was not able to identify more POS TAG features and so I have only removed the NNP for an instance which will at least help remove naming words such as 'george' or words such as 'applicant', 'respondent', etc. \n",
    "\n",
    "So, we can see more POS TAG features as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
